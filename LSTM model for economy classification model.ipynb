{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...   \n",
       "1  b'An American citizen living in S.Ossetia blam...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...   \n",
       "3             b'Russian forces sink Georgian ships '   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the training sets and testing sets\n",
    "\n",
    "train = data[data['Date'] < '2015-01-01']\n",
    "test = data[data['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process the headline into string, for later convinience\n",
    "\n",
    "trainheadlines = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 31675)\n"
     ]
    }
   ],
   "source": [
    "#convert the training set into matrix form\n",
    "\n",
    "basicvectorizer = CountVectorizer()\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "print(basictrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first, we will try to use logistic regreesion since this is a classification problem\n",
    "\n",
    "LogicModel = LogisticRegression()\n",
    "LogicModel = LogicModel.fit(basictrain, train[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting the est lines into string form\n",
    "\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "basictest = basicvectorizer.transform(testheadlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using sklearn library to check the accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "predictions1 = LogicModel.predict(basictest)\n",
    "accuracy1=accuracy_score(test['Label'], predictions1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logic Regression 1 accuracy:  0.425925925926\n"
     ]
    }
   ],
   "source": [
    "print('Logic Regression 1 accuracy: ', accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not so good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19419</th>\n",
       "      <td>0.497924</td>\n",
       "      <td>nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261</th>\n",
       "      <td>0.452526</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29286</th>\n",
       "      <td>0.428011</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0.425863</td>\n",
       "      <td>korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>0.425716</td>\n",
       "      <td>olympics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient      Word\n",
       "19419     0.497924   nigeria\n",
       "25261     0.452526      self\n",
       "29286     0.428011        tv\n",
       "15998     0.425863     korea\n",
       "20135     0.425716  olympics"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the fitted parameters\n",
    "\n",
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = LogicModel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19419</th>\n",
       "      <td>0.497924</td>\n",
       "      <td>nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261</th>\n",
       "      <td>0.452526</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29286</th>\n",
       "      <td>0.428011</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0.425863</td>\n",
       "      <td>korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>0.425716</td>\n",
       "      <td>olympics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient      Word\n",
       "19419     0.497924   nigeria\n",
       "25261     0.452526      self\n",
       "29286     0.428011        tv\n",
       "15998     0.425863     korea\n",
       "20135     0.425716  olympics"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16949</th>\n",
       "      <td>-0.463116</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>-0.470454</td>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>-0.494555</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24754</th>\n",
       "      <td>-0.549725</td>\n",
       "      <td>sanctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24542</th>\n",
       "      <td>-0.587794</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient       Word\n",
       "16949    -0.463116        low\n",
       "3651     -0.470454      begin\n",
       "25433    -0.494555        sex\n",
       "24754    -0.549725  sanctions\n",
       "24542    -0.587794        run"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will try logistic model again, but this time\n",
    "#we will set trstriction on training set\n",
    "\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (2, 2))\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 657)\n"
     ]
    }
   ],
   "source": [
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advancedmodel = LogisticRegression()\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making predictions\n",
    "\n",
    "preds2 = advancedmodel.predict(advancedtest)\n",
    "acc2=accuracy_score(test['Label'], preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logic Regression 2 accuracy:  0.571428571429\n"
     ]
    }
   ],
   "source": [
    "print('Logic Regression 2 accuracy: ', acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.264377</td>\n",
       "      <td>set to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.259669</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.216202</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.166895</td>\n",
       "      <td>likely to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.128663</td>\n",
       "      <td>after the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient      Words\n",
       "411     1.264377     set to\n",
       "31      1.259669  and other\n",
       "391     1.216202   right to\n",
       "276     1.166895  likely to\n",
       "14      1.128663  after the"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = advancedvectorizer.get_feature_names()\n",
    "advcoeffs = advancedmodel.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.264377</td>\n",
       "      <td>set to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.259669</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.216202</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.166895</td>\n",
       "      <td>likely to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.128663</td>\n",
       "      <td>after the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient      Words\n",
       "411     1.264377     set to\n",
       "31      1.259669  and other\n",
       "391     1.216202   right to\n",
       "276     1.166895  likely to\n",
       "14      1.128663  after the"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-1.098193</td>\n",
       "      <td>fire on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.128193</td>\n",
       "      <td>around the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>-1.144952</td>\n",
       "      <td>phone hacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1.146688</td>\n",
       "      <td>up in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-1.393351</td>\n",
       "      <td>the country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient          Words\n",
       "131    -1.098193        fire on\n",
       "40     -1.128193     around the\n",
       "366    -1.144952  phone hacking\n",
       "597    -1.146688          up in\n",
       "452    -1.393351    the country"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Bayes is usually working well on nltk issue, give it a shot\n",
    "\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.1, max_df=0.7, max_features = 200000, ngram_range = (1, 1))\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 529)\n"
     ]
    }
   ],
   "source": [
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import naive bayes library - we have multiple classes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "advancedmodel = MultinomialNB(alpha=0.01)\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds4 = advancedmodel.predict(advancedtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc4=accuracy_score(test['Label'], preds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes 1 accuracy:  0.513227513228\n"
     ]
    }
   ],
   "source": [
    "print('NBayes 1 accuracy: ', acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-5.180422</td>\n",
       "      <td>israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-5.252936</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-5.312797</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-5.317049</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-5.329156</td>\n",
       "      <td>says</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient   Words\n",
       "234    -5.180422  israel\n",
       "497    -5.252936     was\n",
       "94     -5.312797   china\n",
       "318    -5.317049     not\n",
       "394    -5.329156    says"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = advancedvectorizer.get_feature_names()\n",
    "advcoeffs = advancedmodel.coef_.tolist()[0]\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-6.948273</td>\n",
       "      <td>held</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-6.951188</td>\n",
       "      <td>tells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-6.952040</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-6.970522</td>\n",
       "      <td>monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-6.970642</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient   Words\n",
       "204    -6.948273    held\n",
       "446    -6.951188   tells\n",
       "426    -6.952040   story\n",
       "290    -6.970522  monday\n",
       "268    -6.970642    lost"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advancedvectorizer = TfidfVectorizer( min_df=0.03, max_df=0.5, max_features = 200000, ngram_range = (2, 2))\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 654)\n"
     ]
    }
   ],
   "source": [
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advancedmodel = MultinomialNB(alpha=0.0001)\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "preds5 = advancedmodel.predict(advancedtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc5 = accuracy_score(test['Label'], preds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes 2 accuracy:  0.537037037037\n"
     ]
    }
   ],
   "source": [
    "print('NBayes 2 accuracy: ', acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-5.180422</td>\n",
       "      <td>israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-5.252936</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-5.312797</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-5.317049</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-5.329156</td>\n",
       "      <td>says</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient   Words\n",
       "234    -5.180422  israel\n",
       "497    -5.252936     was\n",
       "94     -5.312797   china\n",
       "318    -5.317049     not\n",
       "394    -5.329156    says"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-6.948273</td>\n",
       "      <td>held</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-6.951188</td>\n",
       "      <td>tells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-6.952040</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-6.970522</td>\n",
       "      <td>monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-6.970642</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coefficient   Words\n",
       "204    -6.948273    held\n",
       "446    -6.951188   tells\n",
       "426    -6.952040   story\n",
       "290    -6.970522  monday\n",
       "268    -6.970642    lost"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1611, 613)\n",
      "X_test shape: (1134, 4565)\n"
     ]
    }
   ],
   "source": [
    "X_train = advancedtrain.toarray()\n",
    "X_test = advancedtest.toarray()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(train[\"Label\"])\n",
    "y_test = np.array(test[\"Label\"])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finally, we can try deep learning model as well,\n",
    "#Since this is string classification, LSTM is best option\n",
    "#set up the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1611, 200)\n",
      "X_test shape: (1134, 200)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  if __name__ == '__main__':\n",
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#now we can finally add layers to the model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 401)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.04, max_df=0.3, max_features = 200000, ngram_range = (2, 2))\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1611, 401)\n",
      "X_test shape: (378, 401)\n"
     ]
    }
   ],
   "source": [
    "X_train = advancedtrain.toarray()\n",
    "X_test = advancedtest.toarray()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(train[\"Label\"])\n",
    "y_test = np.array(test[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's a Deep Dumb MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1127 samples, validate on 484 samples\n",
      "Epoch 1/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.7484e-04 - val_loss: 3.9258\n",
      "Epoch 2/64\n",
      "1127/1127 [==============================] - 0s - loss: 5.3705e-05 - val_loss: 3.9340\n",
      "Epoch 3/64\n",
      " 128/1127 [==>...........................] - ETA: 0s - loss: 1.5591e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127/1127 [==============================] - 0s - loss: 1.2301e-04 - val_loss: 3.9652\n",
      "Epoch 4/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.7797e-04 - val_loss: 3.9603\n",
      "Epoch 5/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.3508e-04 - val_loss: 3.9823\n",
      "Epoch 6/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.8570e-05 - val_loss: 3.9929\n",
      "Epoch 7/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.9596e-05 - val_loss: 4.0118\n",
      "Epoch 8/64\n",
      "1127/1127 [==============================] - 0s - loss: 3.1935e-04 - val_loss: 4.0539\n",
      "Epoch 9/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.0682e-04 - val_loss: 4.0353\n",
      "Epoch 10/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.1956e-05 - val_loss: 4.0721\n",
      "Epoch 11/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.9910e-05 - val_loss: 4.0718\n",
      "Epoch 12/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.0644e-05 - val_loss: 4.1032\n",
      "Epoch 13/64\n",
      "1127/1127 [==============================] - 0s - loss: 3.1049e-05 - val_loss: 4.1151\n",
      "Epoch 14/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.6622e-05 - val_loss: 4.1227\n",
      "Epoch 15/64\n",
      "1127/1127 [==============================] - 0s - loss: 0.0011 - val_loss: 4.1204\n",
      "Epoch 16/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.0475e-05 - val_loss: 4.1163\n",
      "Epoch 17/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.1295e-05 - val_loss: 4.1503\n",
      "Epoch 18/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.1331e-05 - val_loss: 4.1735\n",
      "Epoch 19/64\n",
      "1127/1127 [==============================] - 0s - loss: 7.6035e-05 - val_loss: 4.1718\n",
      "Epoch 20/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.2158e-04 - val_loss: 4.2110\n",
      "Epoch 21/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.0810e-05 - val_loss: 4.2308\n",
      "Epoch 22/64\n",
      "1127/1127 [==============================] - 0s - loss: 3.5603e-05 - val_loss: 4.2249\n",
      "Epoch 23/64\n",
      "1127/1127 [==============================] - 0s - loss: 8.9165e-06 - val_loss: 4.2297\n",
      "Epoch 24/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.9939e-05 - val_loss: 4.2133\n",
      "Epoch 25/64\n",
      "1127/1127 [==============================] - 0s - loss: 0.0022 - val_loss: 4.2230\n",
      "Epoch 26/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.2048e-05 - val_loss: 4.2325\n",
      "Epoch 27/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.5478e-05 - val_loss: 4.2121\n",
      "Epoch 28/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.0677e-05 - val_loss: 4.2031\n",
      "Epoch 29/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.1315e-05 - val_loss: 4.2122\n",
      "Epoch 30/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.8906e-05 - val_loss: 4.2278\n",
      "Epoch 31/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.4804e-05 - val_loss: 4.2872\n",
      "Epoch 32/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.4412e-05 - val_loss: 4.2858\n",
      "Epoch 33/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.0763e-05 - val_loss: 4.2963\n",
      "Epoch 34/64\n",
      "1127/1127 [==============================] - 0s - loss: 7.4823e-06 - val_loss: 4.2919\n",
      "Epoch 35/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.2463e-05 - val_loss: 4.3340\n",
      "Epoch 36/64\n",
      "1127/1127 [==============================] - 0s - loss: 4.6212e-05 - val_loss: 4.3991\n",
      "Epoch 37/64\n",
      "1127/1127 [==============================] - 0s - loss: 5.5809e-04 - val_loss: 4.4180\n",
      "Epoch 38/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.5866e-04 - val_loss: 4.4549\n",
      "Epoch 39/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.3332e-06 - val_loss: 4.4523\n",
      "Epoch 40/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.0853e-05 - val_loss: 4.4643\n",
      "Epoch 41/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.4624e-05 - val_loss: 4.4606\n",
      "Epoch 42/64\n",
      "1127/1127 [==============================] - 0s - loss: 8.8066e-05 - val_loss: 4.4720\n",
      "Epoch 43/64\n",
      "1127/1127 [==============================] - 0s - loss: 9.5920e-06 - val_loss: 4.4677\n",
      "Epoch 44/64\n",
      "1127/1127 [==============================] - 0s - loss: 9.2788e-06 - val_loss: 4.5157\n",
      "Epoch 45/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.7147e-05 - val_loss: 4.5306\n",
      "Epoch 46/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.8502e-06 - val_loss: 4.5255\n",
      "Epoch 47/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.2212e-05 - val_loss: 4.5593\n",
      "Epoch 48/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.7544e-06 - val_loss: 4.5888\n",
      "Epoch 49/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.6008e-04 - val_loss: 4.5944\n",
      "Epoch 50/64\n",
      "1127/1127 [==============================] - 0s - loss: 9.2001e-05 - val_loss: 4.6076\n",
      "Epoch 51/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.6593e-06 - val_loss: 4.6241\n",
      "Epoch 52/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.6678e-06 - val_loss: 4.6358\n",
      "Epoch 53/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.8414e-06 - val_loss: 4.6741\n",
      "Epoch 54/64\n",
      "1127/1127 [==============================] - 0s - loss: 6.6329e-06 - val_loss: 4.6854\n",
      "Epoch 55/64\n",
      "1127/1127 [==============================] - 0s - loss: 7.5316e-06 - val_loss: 4.7017\n",
      "Epoch 56/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.5160e-05 - val_loss: 4.7315\n",
      "Epoch 57/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.0360e-06 - val_loss: 4.7391\n",
      "Epoch 58/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.9896e-06 - val_loss: 4.7462\n",
      "Epoch 59/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.9541e-04 - val_loss: 4.6735\n",
      "Epoch 60/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.1139e-04 - val_loss: 4.6637\n",
      "Epoch 61/64\n",
      "1127/1127 [==============================] - 0s - loss: 2.4327e-05 - val_loss: 4.6448\n",
      "Epoch 62/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.5623e-04 - val_loss: 4.6452\n",
      "Epoch 63/64\n",
      "1127/1127 [==============================] - 0s - loss: 1.8915e-05 - val_loss: 4.6682\n",
      "Epoch 64/64\n",
      "1127/1127 [==============================] - 0s - loss: 3.2958e-06 - val_loss: 4.6813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d8f3ef0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=64, batch_size=128, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds14 = model.predict_classes(X_test, verbose=0)\n",
    "acc14 = accuracy_score(test[\"Label\"], preds14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy:  0.547619047619\n"
     ]
    }
   ],
   "source": [
    "print('prediction accuracy: ', acc14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "maxlen = 200\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/keras/preprocessing/text.py:139: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=max_features)\n",
    "tokenizer.fit_on_texts(trainheadlines)\n",
    "sequences_train = tokenizer.texts_to_sequences(trainheadlines)\n",
    "sequences_test = tokenizer.texts_to_sequences(testheadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (1611, 200)\n",
      "X_test shape: (378, 200)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2)) \n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1611 samples, validate on 378 samples\n",
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1611/1611 [==============================] - 29s - loss: 0.0509 - acc: 0.9888 - val_loss: 1.2973 - val_acc: 0.5503\n",
      "Epoch 2/64\n",
      "1611/1611 [==============================] - 30s - loss: 0.0192 - acc: 0.9975 - val_loss: 1.4476 - val_acc: 0.5370\n",
      "Epoch 3/64\n",
      "1611/1611 [==============================] - 30s - loss: 0.0083 - acc: 0.9994 - val_loss: 1.5153 - val_acc: 0.5317\n",
      "Epoch 4/64\n",
      "1611/1611 [==============================] - 30s - loss: 0.0046 - acc: 1.0000 - val_loss: 1.5206 - val_acc: 0.5370\n",
      "Epoch 5/64\n",
      "1611/1611 [==============================] - 30s - loss: 0.0028 - acc: 1.0000 - val_loss: 1.7958 - val_acc: 0.5423\n",
      "Epoch 6/64\n",
      "1611/1611 [==============================] - 28s - loss: 0.0024 - acc: 0.9994 - val_loss: 1.6088 - val_acc: 0.5423\n",
      "Epoch 7/64\n",
      "1611/1611 [==============================] - 29s - loss: 0.0022 - acc: 1.0000 - val_loss: 1.8645 - val_acc: 0.5450\n",
      "Epoch 8/64\n",
      "1611/1611 [==============================] - 29s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.8233 - val_acc: 0.5423\n",
      "Epoch 9/64\n",
      "1611/1611 [==============================] - 37s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.8179 - val_acc: 0.5423\n",
      "Epoch 10/64\n",
      "1611/1611 [==============================] - 36s - loss: 9.8219e-04 - acc: 1.0000 - val_loss: 1.8953 - val_acc: 0.5397\n",
      "Epoch 11/64\n",
      "1611/1611 [==============================] - 47s - loss: 8.2602e-04 - acc: 1.0000 - val_loss: 1.9329 - val_acc: 0.5397\n",
      "Epoch 12/64\n",
      "1611/1611 [==============================] - 55s - loss: 9.2101e-04 - acc: 1.0000 - val_loss: 1.8000 - val_acc: 0.5159\n",
      "Epoch 13/64\n",
      "1611/1611 [==============================] - 71s - loss: 7.0952e-04 - acc: 1.0000 - val_loss: 1.9591 - val_acc: 0.5265\n",
      "Epoch 14/64\n",
      "1611/1611 [==============================] - 69s - loss: 4.6827e-04 - acc: 1.0000 - val_loss: 2.0862 - val_acc: 0.5291\n",
      "Epoch 15/64\n",
      "1611/1611 [==============================] - 50s - loss: 6.4710e-04 - acc: 1.0000 - val_loss: 1.9563 - val_acc: 0.5423\n",
      "Epoch 16/64\n",
      "1611/1611 [==============================] - 29s - loss: 0.0026 - acc: 0.9994 - val_loss: 1.7454 - val_acc: 0.5503\n",
      "Epoch 17/64\n",
      "1611/1611 [==============================] - 29s - loss: 0.0022 - acc: 1.0000 - val_loss: 1.9597 - val_acc: 0.5476\n",
      "Epoch 18/64\n",
      "1611/1611 [==============================] - 29s - loss: 6.2779e-04 - acc: 1.0000 - val_loss: 1.9976 - val_acc: 0.5370\n",
      "Epoch 19/64\n",
      "1611/1611 [==============================] - 29s - loss: 4.8685e-04 - acc: 1.0000 - val_loss: 1.9671 - val_acc: 0.5370\n",
      "Epoch 20/64\n",
      "1611/1611 [==============================] - 29s - loss: 3.6752e-04 - acc: 1.0000 - val_loss: 2.0630 - val_acc: 0.5344\n",
      "Epoch 21/64\n",
      "1611/1611 [==============================] - 29s - loss: 3.8894e-04 - acc: 1.0000 - val_loss: 2.0923 - val_acc: 0.5370\n",
      "Epoch 22/64\n",
      "1611/1611 [==============================] - 29s - loss: 2.8457e-04 - acc: 1.0000 - val_loss: 2.1090 - val_acc: 0.5423\n",
      "Epoch 23/64\n",
      "1611/1611 [==============================] - 29s - loss: 2.9053e-04 - acc: 1.0000 - val_loss: 2.1816 - val_acc: 0.5317\n",
      "Epoch 24/64\n",
      "1611/1611 [==============================] - 29s - loss: 3.5224e-04 - acc: 1.0000 - val_loss: 2.1597 - val_acc: 0.5370\n",
      "Epoch 25/64\n",
      "1611/1611 [==============================] - 29s - loss: 2.9192e-04 - acc: 1.0000 - val_loss: 2.2081 - val_acc: 0.5476\n",
      "Epoch 26/64\n",
      "1611/1611 [==============================] - 29s - loss: 2.1315e-04 - acc: 1.0000 - val_loss: 2.2424 - val_acc: 0.5397\n",
      "Epoch 27/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.9477e-04 - acc: 1.0000 - val_loss: 2.2700 - val_acc: 0.5291\n",
      "Epoch 28/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.3973e-04 - acc: 1.0000 - val_loss: 2.2755 - val_acc: 0.5265\n",
      "Epoch 29/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.8935e-04 - acc: 1.0000 - val_loss: 2.2752 - val_acc: 0.5265\n",
      "Epoch 30/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.7346e-04 - acc: 1.0000 - val_loss: 2.3625 - val_acc: 0.5397\n",
      "Epoch 31/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.5554e-04 - acc: 1.0000 - val_loss: 2.3171 - val_acc: 0.5423\n",
      "Epoch 32/64\n",
      "1611/1611 [==============================] - 32s - loss: 1.2300e-04 - acc: 1.0000 - val_loss: 2.3024 - val_acc: 0.5265\n",
      "Epoch 33/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.0241e-04 - acc: 1.0000 - val_loss: 2.3551 - val_acc: 0.5397\n",
      "Epoch 34/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.0889e-04 - acc: 1.0000 - val_loss: 2.3976 - val_acc: 0.5344\n",
      "Epoch 35/64\n",
      "1611/1611 [==============================] - 32s - loss: 1.0348e-04 - acc: 1.0000 - val_loss: 2.4319 - val_acc: 0.5344\n",
      "Epoch 36/64\n",
      "1611/1611 [==============================] - 32s - loss: 1.6047e-04 - acc: 1.0000 - val_loss: 2.4046 - val_acc: 0.5265\n",
      "Epoch 37/64\n",
      "1611/1611 [==============================] - 33s - loss: 9.5590e-05 - acc: 1.0000 - val_loss: 2.4370 - val_acc: 0.5212\n",
      "Epoch 38/64\n",
      "1611/1611 [==============================] - 31s - loss: 6.5975e-05 - acc: 1.0000 - val_loss: 2.4751 - val_acc: 0.5238\n",
      "Epoch 39/64\n",
      "1611/1611 [==============================] - 29s - loss: 1.3164e-04 - acc: 1.0000 - val_loss: 2.2594 - val_acc: 0.5317\n",
      "Epoch 40/64\n",
      "1611/1611 [==============================] - 33s - loss: 1.0674e-04 - acc: 1.0000 - val_loss: 2.2924 - val_acc: 0.5291\n",
      "Epoch 41/64\n",
      "1611/1611 [==============================] - 31s - loss: 8.6347e-05 - acc: 1.0000 - val_loss: 2.3721 - val_acc: 0.5317\n",
      "Epoch 42/64\n",
      "1611/1611 [==============================] - 31s - loss: 6.0151e-05 - acc: 1.0000 - val_loss: 2.4509 - val_acc: 0.5265\n",
      "Epoch 43/64\n",
      "1611/1611 [==============================] - 31s - loss: 7.7757e-05 - acc: 1.0000 - val_loss: 2.4910 - val_acc: 0.5185\n",
      "Epoch 44/64\n",
      "1611/1611 [==============================] - 31s - loss: 0.0033 - acc: 0.9988 - val_loss: 1.8993 - val_acc: 0.5159\n",
      "Epoch 45/64\n",
      "1611/1611 [==============================] - 30s - loss: 0.0108 - acc: 0.9988 - val_loss: 1.7417 - val_acc: 0.5344\n",
      "Epoch 46/64\n",
      "1611/1611 [==============================] - 29s - loss: 0.0088 - acc: 0.9981 - val_loss: 1.7679 - val_acc: 0.5529\n",
      "Epoch 47/64\n",
      "1611/1611 [==============================] - 31s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.9668 - val_acc: 0.5556\n",
      "Epoch 48/64\n",
      "1611/1611 [==============================] - 33s - loss: 6.1477e-04 - acc: 1.0000 - val_loss: 2.0905 - val_acc: 0.5556\n",
      "Epoch 49/64\n",
      "1611/1611 [==============================] - 29s - loss: 3.7212e-04 - acc: 1.0000 - val_loss: 2.2008 - val_acc: 0.5556\n",
      "Epoch 50/64\n",
      "1611/1611 [==============================] - 31s - loss: 3.3233e-04 - acc: 1.0000 - val_loss: 2.2189 - val_acc: 0.5503\n",
      "Epoch 51/64\n",
      "1611/1611 [==============================] - 32s - loss: 3.8864e-04 - acc: 1.0000 - val_loss: 2.2076 - val_acc: 0.5608\n",
      "Epoch 52/64\n",
      "1611/1611 [==============================] - 30s - loss: 2.0873e-04 - acc: 1.0000 - val_loss: 2.3030 - val_acc: 0.5529\n",
      "Epoch 53/64\n",
      "1611/1611 [==============================] - 29s - loss: 1.9496e-04 - acc: 1.0000 - val_loss: 2.3725 - val_acc: 0.5635\n",
      "Epoch 54/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.5131e-04 - acc: 1.0000 - val_loss: 2.4106 - val_acc: 0.5503\n",
      "Epoch 55/64\n",
      "1611/1611 [==============================] - 29s - loss: 1.1023e-04 - acc: 1.0000 - val_loss: 2.4481 - val_acc: 0.5503\n",
      "Epoch 56/64\n",
      "1611/1611 [==============================] - 29s - loss: 1.4892e-04 - acc: 1.0000 - val_loss: 2.3614 - val_acc: 0.5503\n",
      "Epoch 57/64\n",
      "1611/1611 [==============================] - 30s - loss: 9.4282e-05 - acc: 1.0000 - val_loss: 2.3992 - val_acc: 0.5450\n",
      "Epoch 58/64\n",
      "1611/1611 [==============================] - 29s - loss: 9.6725e-05 - acc: 1.0000 - val_loss: 2.4471 - val_acc: 0.5423\n",
      "Epoch 59/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.1240e-04 - acc: 1.0000 - val_loss: 2.4780 - val_acc: 0.5503\n",
      "Epoch 60/64\n",
      "1611/1611 [==============================] - 30s - loss: 1.1488e-04 - acc: 1.0000 - val_loss: 2.5256 - val_acc: 0.5476\n",
      "Epoch 61/64\n",
      "1611/1611 [==============================] - 29s - loss: 8.7085e-05 - acc: 1.0000 - val_loss: 2.5306 - val_acc: 0.5450\n",
      "Epoch 62/64\n",
      "1611/1611 [==============================] - 32s - loss: 7.6046e-05 - acc: 1.0000 - val_loss: 2.5240 - val_acc: 0.5529\n",
      "Epoch 63/64\n",
      "1611/1611 [==============================] - 30s - loss: 6.7039e-05 - acc: 1.0000 - val_loss: 2.5063 - val_acc: 0.5476\n",
      "Epoch 64/64\n",
      "1611/1611 [==============================] - 30s - loss: 5.7826e-05 - acc: 1.0000 - val_loss: 2.5418 - val_acc: 0.5503\n",
      "378/378 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=64, \n",
    "          nb_epoch=64,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score, acc = model.evaluate(X_test, Y_test,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 2.54180836362\n",
      "Test accuracy: 0.550264549949\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds15 = model.predict_classes(X_test, verbose=0)\n",
    "acc15 = accuracy_score(test['Label'], preds15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy:  0.550264550265\n"
     ]
    }
   ],
   "source": [
    "print('prediction accuracy: ', acc15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training model looks good, we can do some regularization & dropout if this is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
